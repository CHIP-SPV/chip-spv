In all Earlier tutorial we used single stream, In this tutorial, we\textquotesingle{}ll explain how to launch multiple streams.\hypertarget{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_samples_2__cookbook_7_streams__readme_autotoc_md942}{}\doxysection{Introduction\+:}\label{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_samples_2__cookbook_7_streams__readme_autotoc_md942}
The various instances of kernel to be executed on device in exact launch order defined by Host are called streams. We can launch multiple streams on a single device. We will learn how to learn two streams which can we scaled with ease.\hypertarget{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_samples_2__cookbook_7_streams__readme_autotoc_md943}{}\doxysection{Requirement\+:}\label{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_samples_2__cookbook_7_streams__readme_autotoc_md943}
For hardware requirement and software installation \href{https://github.com/ROCm-Developer-Tools/HIP/blob/master/INSTALL.md}{\texttt{ Installation}}\hypertarget{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_samples_2__cookbook_7_streams__readme_autotoc_md944}{}\doxysection{prerequiste knowledge\+:}\label{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_samples_2__cookbook_7_streams__readme_autotoc_md944}
Programmers familiar with CUDA, Open\+CL will be able to quickly learn and start coding with the HIP API. In case you are not, don\textquotesingle{}t worry. You choose to start with the best one. We\textquotesingle{}ll be explaining everything assuming you are completely new to gpgpu programming.\hypertarget{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_samples_2__cookbook_7_streams__readme_autotoc_md945}{}\doxysection{Simple Matrix Transpose}\label{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_samples_2__cookbook_7_streams__readme_autotoc_md945}
We will be using the Simple Matrix Transpose application from the previous tutorial and modify it to learn how to launch multiple streams.\hypertarget{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_samples_2__cookbook_7_streams__readme_autotoc_md946}{}\doxysection{Streams}\label{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_samples_2__cookbook_7_streams__readme_autotoc_md946}
In this tutorial, we\textquotesingle{}ll use both instances of shared memory (i.\+e., static and dynamic) as different streams. We declare stream as follows\+: {\ttfamily hip\+Stream\+\_\+t streams\mbox{[}num\+\_\+streams\mbox{]};}

and create stream using {\ttfamily hip\+Stream\+Create} as follows\+: 
\begin{DoxyCode}{0}
\DoxyCodeLine{for(int i=0;i<num\_streams;i++)}
\DoxyCodeLine{    hipStreamCreate(\&streams[i]);}

\end{DoxyCode}


and while kernel launch, we make the following changes in 5th parameter to hip\+Launch\+Kernel\+GGL(having 0 as the default stream value)\+:


\begin{DoxyCode}{0}
\DoxyCodeLine{hipLaunchKernelGGL(matrixTranspose\_static\_shared,}
\DoxyCodeLine{                   dim3(WIDTH/THREADS\_PER\_BLOCK\_X, WIDTH/THREADS\_PER\_BLOCK\_Y),}
\DoxyCodeLine{                   dim3(THREADS\_PER\_BLOCK\_X, THREADS\_PER\_BLOCK\_Y),}
\DoxyCodeLine{                   0, streams[0],}
\DoxyCodeLine{                   gpuTransposeMatrix[0], data[0], width);}

\end{DoxyCode}



\begin{DoxyCode}{0}
\DoxyCodeLine{hipLaunchKernelGGL(matrixTranspose\_dynamic\_shared,}
\DoxyCodeLine{                   dim3(WIDTH/THREADS\_PER\_BLOCK\_X, WIDTH/THREADS\_PER\_BLOCK\_Y),}
\DoxyCodeLine{                   dim3(THREADS\_PER\_BLOCK\_X, THREADS\_PER\_BLOCK\_Y),}
\DoxyCodeLine{                   sizeof(float)*WIDTH*WIDTH, streams[1],}
\DoxyCodeLine{                   gpuTransposeMatrix[1], data[1], width);}

\end{DoxyCode}


here we replaced 4th parameter with amount of additional shared memory to allocate when launching the kernel.\hypertarget{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_samples_2__cookbook_7_streams__readme_autotoc_md947}{}\doxysection{How to build and run\+:}\label{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_samples_2__cookbook_7_streams__readme_autotoc_md947}
Use the make command and execute it using ./exe Use hipcc to build the application, which is using hcc on AMD and nvcc on nvidia.\hypertarget{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_samples_2__cookbook_7_streams__readme_autotoc_md948}{}\doxysection{More Info\+:}\label{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_samples_2__cookbook_7_streams__readme_autotoc_md948}

\begin{DoxyItemize}
\item \href{https://github.com/ROCm-Developer-Tools/HIP/blob/master/docs/markdown/hip_faq.md}{\texttt{ HIP FAQ}}
\item \href{https://github.com/ROCm-Developer-Tools/HIP/blob/master/docs/markdown/hip_kernel_language.md}{\texttt{ HIP Kernel Language}}
\item \href{http://rocm-developer-tools.github.io/HIP}{\texttt{ HIP Runtime API (Doxygen)}}
\item \href{https://github.com/ROCm-Developer-Tools/HIP/blob/master/docs/markdown/hip_porting_guide.md}{\texttt{ HIP Porting Guide}}
\item \href{https://github.com/ROCm-Developer-Tools/HIP/blob/master/docs/markdown/hip_terms.md}{\texttt{ HIP Terminology}} (including Rosetta Stone of GPU computing terms across CUDA/\+HIP/\+HC/\+AMP/\+OpenL)
\item \href{https://github.com/ROCm-Developer-Tools/HIPIFY/blob/master/README.md}{\texttt{ HIPIFY}}
\item \href{https://github.com/ROCm-Developer-Tools/HIP/blob/master/CONTRIBUTING.md}{\texttt{ Developer/\+CONTRIBUTING Info}}
\item \href{https://github.com/ROCm-Developer-Tools/HIP/blob/master/RELEASE.md}{\texttt{ Release Notes}} 
\end{DoxyItemize}