\hypertarget{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md696}{}\doxysection{Introduction to the CUDA Driver and Runtime APIs}\label{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md696}
CUDA provides a separate CUDA Driver and Runtime APIs. The two APIs have significant overlap in functionality\+:
\begin{DoxyItemize}
\item Both APIs support events, streams, memory management, memory copy, and error handling.
\item Both APIs deliver similar performance.
\item Driver APIs calls begin with the prefix {\ttfamily cu} while Runtime APIs begin with the prefix {\ttfamily cuda}. For example, the Driver API API contains {\ttfamily cu\+Event\+Create} while the Runtime API contains {\ttfamily cuda\+Event\+Create}, with similar functionality.
\item The Driver API defines a different but largely overlapping error code space than the Runtime API, and uses a different coding convention. For example, Driver API defines {\ttfamily CUDA\+\_\+\+ERROR\+\_\+\+INVALID\+\_\+\+VALUE} while the Runtime API defines {\ttfamily cuda\+Error\+Invalid\+Value}
\end{DoxyItemize}

The Driver API offers two additional pieces of functionality not provided by the Runtime API\+: cu\+Module and cu\+Ctx APIs.\hypertarget{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md697}{}\doxysubsection{cu\+Module API}\label{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md697}
The Module section of the Driver API provides additional control over how and when accelerator code objects are loaded. For example, the driver API allows code objects to be loaded from files or memory pointers. Symbols for kernels or global data can be extracted from the loaded code objects. In contrast, the Runtime API automatically loads and (if necessary) compiles all of the kernels from an executable binary when run. In this mode, NVCC must be used to compile kernel code so the automatic loading can function correctly.

Both Driver and Runtime APIs define a function for launching kernels (called {\ttfamily cu\+Launch\+Kernel} or {\ttfamily cuda\+Launch\+Kernel}. The kernel arguments and the execution configuration (grid dimensions, group dimensions, dynamic shared memory, and stream) are passed as arguments to the launch function. The Runtime additionally provides the {\ttfamily \texorpdfstring{$<$}{<}\texorpdfstring{$<$}{<}\texorpdfstring{$<$}{<} \texorpdfstring{$>$}{>}\texorpdfstring{$>$}{>}\texorpdfstring{$>$}{>}} syntax for launching kernels, which resembles a special function call and is easier to use than explicit launch API (in particular with respect to handling of kernel arguments). However, this syntax is not standard C++ and is available only when NVCC is used to compile the host code.

The Module features are useful in an environment which generates the code objects directly, such as a new accelerator language front-\/end. Here, NVCC is not used. Instead, the environment may have a different kernel language or different compilation flow. Other environments have many kernels and do not want them to be all loaded automatically. The Module functions can be used to load the generated code objects and launch kernels. As we will see below, HIP defines a Module API which provides similar explicit control over code object management.\hypertarget{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md698}{}\doxysubsection{cu\+Ctx API}\label{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md698}
The Driver API defines \char`\"{}\+Context\char`\"{} and \char`\"{}\+Devices\char`\"{} as separate entities. Contexts contain a single device, and a device can theoretically have multiple contexts. Each context contains a set of streams and events specific to the context. Historically contexts also defined a unique address space for the GPU, though this may no longer be the case in Unified Memory platforms (since the CPU and all the devices in the same process share a single unified address space). The Context APIs also provide a mechanism to switch between devices, which allowed a single CPU thread to send commands to different GPUs. HIP as well as a recent versions of CUDA Runtime provide other mechanisms to accomplish this feat -\/ for example using streams or {\ttfamily cuda\+Set\+Device}.

The CUDA Runtime API unifies the Context API with the Device API. This simplifies the APIs and has little loss of functionality since each Context can contain a single device, and the benefits of multiple contexts has been replaced with other interfaces. HIP provides a context API to facilitate easy porting from existing Driver codes. In HIP, the Ctx functions largely provide an alternate syntax for changing the active device.

Most new applications will prefer to use {\ttfamily hip\+Set\+Device} or the stream APIs , therefore HIP has marked hip\+Ctx APIs as {\bfseries{deprecated}}. Support for these APIs may not be available in future releases. For more details on deprecated APIs please refer \href{https://github.com/ROCm-Developer-Tools/HIP/tree/master/docs/markdown/hip_deprecated_api_list.md}{\texttt{ HIP deprecated APIs}}.\hypertarget{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md699}{}\doxysection{HIP Module and Ctx APIs}\label{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md699}
Rather than present two separate APIs, HIP extends the HIP API with new APIs for Modules and Ctx control.\hypertarget{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md700}{}\doxysubsection{hip\+Module API}\label{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md700}
Like the CUDA Driver API, the Module API provides additional control over how code is loaded, including options to load code from files or from in-\/memory pointers. NVCC and HIP-\/\+Clang target different architectures and use different code object formats\+: NVCC is {\ttfamily cubin} or {\ttfamily ptx} files, while the HIP-\/\+Clang path is the {\ttfamily hsaco} format. The external compilers which generate these code objects are responsible for generating and loading the correct code object for each platform. Notably, there is not a fat binary format that can contain code for both NVCC and HIP-\/\+Clang platforms. The following table summarizes the formats used on each platform\+:

\tabulinesep=1mm
\begin{longtabu}spread 0pt [c]{*{4}{|X[-1]}|}
\hline
\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Format   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ APIs   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ NVCC   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ HIP-\/\+CLANG    }\\\cline{1-4}
\endfirsthead
\hline
\endfoot
\hline
\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Format   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ APIs   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ NVCC   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ HIP-\/\+CLANG    }\\\cline{1-4}
\endhead
Code Object   &hip\+Module\+Load, hip\+Module\+Load\+Data   &.cubin or PTX text   &.hsaco    \\\cline{1-4}
Fat Binary   &hip\+Module\+Load\+Fat\+Bin   &.fatbin   &.hip\+\_\+fatbin   \\\cline{1-4}
\end{longtabu}


{\ttfamily hipcc} uses HIP-\/\+Clang or NVCC to compile host codes. Both of these may embed code objects into the final executable, and these code objects will be automatically loaded when the application starts. The hip\+Module API can be used to load additional code objects, and in this way provides an extended capability to the automatically loaded code objects. HIP-\/\+Clang allows both of these capabilities to be used together, if desired. Of course it is possible to create a program with no kernels and thus no automatic loading.\hypertarget{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md701}{}\doxysubsection{hip\+Ctx API}\label{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md701}
HIP provides a {\ttfamily Ctx} API as a thin layer over the existing Device functions. This Ctx API can be used to set the current context, or to query properties of the device associated with the context. The current context is implicitly used by other APIs such as {\ttfamily hip\+Stream\+Create}.\hypertarget{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md702}{}\doxysubsection{hipify translation of CUDA Driver API}\label{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md702}
The HIPIFY tools convert CUDA Driver APIs for streams, events, modules, devices, memory management, context, profiler to the equivalent HIP driver calls. For example, {\ttfamily cu\+Event\+Create} will be translated to {\ttfamily hip\+Event\+Create}. HIPIFY tools also convert error codes from the Driver namespace and coding convention to the equivalent HIP error code. Thus, HIP unifies the APIs for these common functions.

The memory copy API requires additional explanation. The CUDA driver includes the memory direction in the name of the API (ie {\ttfamily cu\+Memcpy\+H2D}) while the CUDA driver API provides a single memory copy API with a parameter that specifies the direction and additionally supports a \char`\"{}default\char`\"{} direction where the runtime determines the direction automatically. HIP provides APIs with both styles\+: for example, {\ttfamily hip\+Memcpy\+H2D} as well as {\ttfamily hip\+Memcpy}. The first flavor may be faster in some cases since they avoid host overhead to detect the different memory directions.

HIP defines a single error space, and uses camel-\/case for all errors (i.\+e. {\ttfamily hip\+Error\+Invalid\+Value}).\hypertarget{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md703}{}\doxysubsubsection{Address Spaces}\label{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md703}
HIP-\/\+Clang defines a process-\/wide address space where the CPU and all devices allocate addresses from a single unified pool. Thus addresses may be shared between contexts, and unlike the original CUDA definition a new context does not create a new address space for the device.\hypertarget{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md704}{}\doxysubsubsection{Using hip\+Module\+Launch\+Kernel}\label{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md704}
{\ttfamily hip\+Module\+Launch\+Kernel} is {\ttfamily cu\+Launch\+Kernel} in HIP world. It takes the same arguments as {\ttfamily cu\+Launch\+Kernel}.\hypertarget{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md705}{}\doxysubsubsection{Additional Information}\label{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md705}

\begin{DoxyItemize}
\item HIP-\/\+Clang creates a primary context when the HIP API is called. So in a pure driver API code, HIP-\/\+Clang will create a primary context while HIP/\+NVCC will have empty context stack. HIP-\/\+Clang will push primary context to context stack when it is empty. This can have subtle differences on applications which mix the runtime and driver APIs.
\end{DoxyItemize}\hypertarget{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md706}{}\doxysubsection{hip-\/clang Implementation Notes}\label{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md706}
\hypertarget{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md707}{}\doxysubsubsection{.\+hip\+\_\+fatbin}\label{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md707}
hip-\/clang links device code from different translation units together. For each device target, a code object is generated. Code objects for different device targets are bundled by clang-\/offload-\/bundler as one fatbinary, which is embeded as a global symbol {\ttfamily \+\_\+\+\_\+hip\+\_\+fatbin} in the .hip\+\_\+fatbin section of the ELF file of the executable or shared object.\hypertarget{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md708}{}\doxysubsubsection{Initialization and Termination Functions}\label{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md708}
hip-\/clang generates initializatiion and termination functions for each translation unit for host code compilation. The initialization functions call {\ttfamily \+\_\+\+\_\+hip\+Register\+Fat\+Binary} to register the fatbinary embeded in the ELF file. They also call {\ttfamily \+\_\+\+\_\+hip\+Register\+Function} and {\ttfamily \+\_\+\+\_\+hip\+Register\+Var} to register kernel functions and device side global variables. The termination functions call {\ttfamily \+\_\+\+\_\+hip\+Unregister\+Fat\+Binary}. hip-\/clang emits a global variable {\ttfamily \+\_\+\+\_\+hip\+\_\+gpubin\+\_\+handle} of void$\ast$$\ast$ type with linkonce linkage and inital value 0 for each host translation unit. Each initialization function checks {\ttfamily \+\_\+\+\_\+hip\+\_\+gpubin\+\_\+handle} and register the fatbinary only if {\ttfamily \+\_\+\+\_\+hip\+\_\+gpubin\+\_\+handle} is 0 and saves the return value of {\ttfamily \+\_\+\+\_\+hip\+\_\+gpubin\+\_\+handle} to {\ttfamily \+\_\+\+\_\+hip\+\_\+gpubin\+\_\+handle}. This is to guarantee that the fatbinary is only registered once. Similar check is done in the termination functions.\hypertarget{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md709}{}\doxysubsubsection{Kernel Launching}\label{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md709}
hip-\/clang supports kernel launching by CUDA {\ttfamily \texorpdfstring{$<$}{<}\texorpdfstring{$<$}{<}\texorpdfstring{$<$}{<}\texorpdfstring{$>$}{>}\texorpdfstring{$>$}{>}\texorpdfstring{$>$}{>}} syntax, hip\+Launch\+Kernel, and hip\+Launch\+Kernel\+GGL. The latter two are macros which expand to CUDA {\ttfamily \texorpdfstring{$<$}{<}\texorpdfstring{$<$}{<}\texorpdfstring{$<$}{<}\texorpdfstring{$>$}{>}\texorpdfstring{$>$}{>}\texorpdfstring{$>$}{>}} syntax.

When the executable or shared library is loaded by the dynamic linker, the initilization functions are called. In the initialization functions, when {\ttfamily \+\_\+\+\_\+hip\+Register\+Fat\+Binary} is called, the code objects containing all kernels are loaded; when {\ttfamily \+\_\+\+\_\+hip\+Register\+Function} is called, the stub functions are associated with the corresponding kernels in code objects.

hip-\/clang implements two sets of kernel launching APIs.

By default, in the host code, for the {\ttfamily \texorpdfstring{$<$}{<}\texorpdfstring{$<$}{<}\texorpdfstring{$<$}{<}\texorpdfstring{$>$}{>}\texorpdfstring{$>$}{>}\texorpdfstring{$>$}{>}} statement, hip-\/clang first emits call of hip\+Configure\+Call to set up the threads and grids, then emits call of the stub function with the given arguments. In the stub function, hip\+Setup\+Argument is called for each kernel argument, then hip\+Launch\+By\+Ptr is called with a function pointer to the stub function. In hip\+Launch\+By\+Ptr, the real kernel associated with the stub function is launched.

If HIP program is compiled with -\/fhip-\/new-\/launch-\/api, in the host code, for the {\ttfamily \texorpdfstring{$<$}{<}\texorpdfstring{$<$}{<}\texorpdfstring{$<$}{<}\texorpdfstring{$>$}{>}\texorpdfstring{$>$}{>}\texorpdfstring{$>$}{>}} statement, hip-\/clang first emits call of {\ttfamily \+\_\+\+\_\+hip\+Push\+Call\+Configuration} to save the grid dimension, block dimension, shared memory usage and stream to a stack, then emits call of the stub function with the given arguments. In the stub function, {\ttfamily \+\_\+\+\_\+hip\+Pop\+Call\+Configuration} is called to get the saved grid dimension, block dimension, shared memory usage and stream, then hip\+Launch\+Kernel is called with a function pointer to the stub function. In hip\+Launch\+Kernel, the real kernel associated with the stub function is launched.\hypertarget{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md710}{}\doxysubsection{NVCC Implementation Notes}\label{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md710}
\hypertarget{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md711}{}\doxysubsubsection{Interoperation between HIP and CUDA Driver}\label{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md711}
CUDA applications may want to mix CUDA driver code with HIP code (see example below). This table shows the type equivalence to enable this interaction.

\tabulinesep=1mm
\begin{longtabu}spread 0pt [c]{*{3}{|X[-1]}|}
\hline
\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ {\bfseries{HIP Type}}   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ {\bfseries{CU Driver Type}}   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ {\bfseries{CUDA Runtime Type}}    }\\\cline{1-3}
\endfirsthead
\hline
\endfoot
\hline
\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ {\bfseries{HIP Type}}   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ {\bfseries{CU Driver Type}}   }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ {\bfseries{CUDA Runtime Type}}    }\\\cline{1-3}
\endhead
hip\+Module\+\_\+t   &CUmodule   &\\\cline{1-3}
hip\+Function\+\_\+t   &CUfunction   &\\\cline{1-3}
hip\+Ctx\+\_\+t   &CUcontext   &\\\cline{1-3}
hip\+Device\+\_\+t   &CUdevice   &\\\cline{1-3}
hip\+Stream\+\_\+t   &CUstream   &cuda\+Stream\+\_\+t    \\\cline{1-3}
hip\+Event\+\_\+t   &CUevent   &cuda\+Event\+\_\+t    \\\cline{1-3}
hip\+Array   &CUarray   &cuda\+Array   \\\cline{1-3}
\end{longtabu}
\hypertarget{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md712}{}\doxysubsubsection{Compilation Options}\label{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md712}
The {\ttfamily hip\+Module\+\_\+t} interface does not support {\ttfamily cu\+Module\+Load\+Data\+Ex} function, which is used to control PTX compilation options. HIP-\/\+Clang does not use PTX and does not support these compilation options. In fact, HIP-\/\+Clang code objects always contain fully compiled ISA and do not require additional compilation as a part of the load step. The corresponding HIP function {\ttfamily hip\+Module\+Load\+Data\+Ex} behaves as {\ttfamily hip\+Module\+Load\+Data} on HIP-\/\+Clang path (compilation options are not used) and as {\ttfamily cu\+Module\+Load\+Data\+Ex} on NVCC path. For example (CUDA)\+: 
\begin{DoxyCode}{0}
\DoxyCodeLine{CUmodule module;}
\DoxyCodeLine{void *imagePtr = ...;  // Somehow populate data pointer with code object}
\DoxyCodeLine{}
\DoxyCodeLine{const int numOptions = 1;}
\DoxyCodeLine{CUJit\_option options[numOptions];}
\DoxyCodeLine{void * optionValues[numOptions];}
\DoxyCodeLine{}
\DoxyCodeLine{options[0] = CU\_JIT\_MAX\_REGISTERS;}
\DoxyCodeLine{unsigned maxRegs = 15;}
\DoxyCodeLine{optionValues[0] = (void*)(\&maxRegs);}
\DoxyCodeLine{}
\DoxyCodeLine{cuModuleLoadDataEx(module, imagePtr, numOptions, options, optionValues);}
\DoxyCodeLine{}
\DoxyCodeLine{CUfunction k;}
\DoxyCodeLine{cuModuleGetFunction(\&k, module, "{}myKernel"{});}

\end{DoxyCode}
 HIP\+: 
\begin{DoxyCode}{0}
\DoxyCodeLine{hipModule\_t module;}
\DoxyCodeLine{void *imagePtr = ...;  // Somehow populate data pointer with code object}
\DoxyCodeLine{}
\DoxyCodeLine{const int numOptions = 1;}
\DoxyCodeLine{hipJitOption options[numOptions];}
\DoxyCodeLine{void * optionValues[numOptions];}
\DoxyCodeLine{}
\DoxyCodeLine{options[0] = hipJitOptionMaxRegisters;}
\DoxyCodeLine{unsigned maxRegs = 15;}
\DoxyCodeLine{optionValues[0] = (void*)(\&maxRegs);}
\DoxyCodeLine{}
\DoxyCodeLine{// hipModuleLoadData(module, imagePtr) will be called on HIP-\/Clang path, JIT options will not be used, and}
\DoxyCodeLine{// cupModuleLoadDataEx(module, imagePtr, numOptions, options, optionValues) will be called on NVCC path}
\DoxyCodeLine{hipModuleLoadDataEx(module, imagePtr, numOptions, options, optionValues);}
\DoxyCodeLine{}
\DoxyCodeLine{hipFunction\_t k;}
\DoxyCodeLine{hipModuleGetFunction(\&k, module, "{}myKernel"{});}

\end{DoxyCode}


The below sample shows how to use {\ttfamily hip\+Module\+Get\+Function}.


\begin{DoxyCode}{0}
\DoxyCodeLine{\#include<hip\_runtime.h>}
\DoxyCodeLine{\#include<hip\_runtime\_api.h>}
\DoxyCodeLine{\#include<iostream>}
\DoxyCodeLine{\#include<fstream>}
\DoxyCodeLine{\#include<vector>}
\DoxyCodeLine{}
\DoxyCodeLine{\#define LEN 64}
\DoxyCodeLine{\#define SIZE LEN<<2}
\DoxyCodeLine{}
\DoxyCodeLine{\#ifdef \_\_HIP\_PLATFORM\_AMD\_\_}
\DoxyCodeLine{\#define fileName "{}vcpy\_isa.co"{}}
\DoxyCodeLine{\#endif}
\DoxyCodeLine{}
\DoxyCodeLine{\#ifdef \_\_HIP\_PLATFORM\_NVIDIA\_\_}
\DoxyCodeLine{\#define fileName "{}vcpy\_isa.ptx"{}}
\DoxyCodeLine{\#endif}
\DoxyCodeLine{}
\DoxyCodeLine{\#define kernel\_name "{}hello\_world"{}}
\DoxyCodeLine{}
\DoxyCodeLine{int main()\{}
\DoxyCodeLine{    float *A, *B;}
\DoxyCodeLine{    hipDeviceptr\_t Ad, Bd;}
\DoxyCodeLine{    A = new float[LEN];}
\DoxyCodeLine{    B = new float[LEN];}
\DoxyCodeLine{}
\DoxyCodeLine{    for(uint32\_t i=0;i<LEN;i++)\{}
\DoxyCodeLine{        A[i] = i*1.0f;}
\DoxyCodeLine{        B[i] = 0.0f;}
\DoxyCodeLine{        std::cout<<A[i] << "{} "{}<<B[i]<<std::endl;}
\DoxyCodeLine{    \}}
\DoxyCodeLine{}
\DoxyCodeLine{}
\DoxyCodeLine{\#ifdef \_\_HIP\_PLATFORM\_NVIDIA\_\_}
\DoxyCodeLine{          hipInit(0);}
\DoxyCodeLine{          hipDevice\_t device;}
\DoxyCodeLine{          hipCtx\_t context;}
\DoxyCodeLine{          hipDeviceGet(\&device, 0);}
\DoxyCodeLine{          hipCtxCreate(\&context, 0, device);}
\DoxyCodeLine{\#endif}
\DoxyCodeLine{}
\DoxyCodeLine{    hipMalloc((void**)\&Ad, SIZE);}
\DoxyCodeLine{    hipMalloc((void**)\&Bd, SIZE);}
\DoxyCodeLine{}
\DoxyCodeLine{    hipMemcpyHtoD(Ad, A, SIZE);}
\DoxyCodeLine{    hipMemcpyHtoD(Bd, B, SIZE);}
\DoxyCodeLine{    hipModule\_t Module;}
\DoxyCodeLine{    hipFunction\_t Function;}
\DoxyCodeLine{    hipModuleLoad(\&Module, fileName);}
\DoxyCodeLine{    hipModuleGetFunction(\&Function, Module, kernel\_name);}
\DoxyCodeLine{}
\DoxyCodeLine{    std::vector<void*>argBuffer(2);}
\DoxyCodeLine{    memcpy(\&argBuffer[0], \&Ad, sizeof(void*));}
\DoxyCodeLine{    memcpy(\&argBuffer[1], \&Bd, sizeof(void*));}
\DoxyCodeLine{}
\DoxyCodeLine{    size\_t size = argBuffer.size()*sizeof(void*);}
\DoxyCodeLine{}
\DoxyCodeLine{    void *config[] = \{}
\DoxyCodeLine{      HIP\_LAUNCH\_PARAM\_BUFFER\_POINTER, \&argBuffer[0],}
\DoxyCodeLine{      HIP\_LAUNCH\_PARAM\_BUFFER\_SIZE, \&size,}
\DoxyCodeLine{      HIP\_LAUNCH\_PARAM\_END}
\DoxyCodeLine{    \};}
\DoxyCodeLine{}
\DoxyCodeLine{    hipModuleLaunchKernel(Function, 1, 1, 1, LEN, 1, 1, 0, 0, NULL, (void**)\&config);}
\DoxyCodeLine{}
\DoxyCodeLine{    hipMemcpyDtoH(B, Bd, SIZE);}
\DoxyCodeLine{    for(uint32\_t i=0;i<LEN;i++)\{}
\DoxyCodeLine{        std::cout<<A[i]<<"{} -\/ "{}<<B[i]<<std::endl;}
\DoxyCodeLine{    \}}
\DoxyCodeLine{}
\DoxyCodeLine{\#ifdef \_\_HIP\_PLATFORM\_NVIDIA\_\_}
\DoxyCodeLine{          hipCtxDetach(context);}
\DoxyCodeLine{\#endif}
\DoxyCodeLine{}
\DoxyCodeLine{    return 0;}
\DoxyCodeLine{\}}

\end{DoxyCode}
\hypertarget{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md713}{}\doxysection{HIP Module and Texture Driver API}\label{md___users_pvelesko_local__c_h_i_p__s_p_v__h_i_p_docs_markdown_hip_porting_driver_api_autotoc_md713}
HIP supports texture driver APIs however texture reference should be declared in host scope. Following code explains the use of texture reference for {\bfseries{HIP\+\_\+\+PLATFORM\+\_\+\+AMD}} platform.


\begin{DoxyCode}{0}
\DoxyCodeLine{// Code to generate code object}
\DoxyCodeLine{}
\DoxyCodeLine{\#include "{}hip/hip\_runtime.h"{}}
\DoxyCodeLine{extern texture<float, 2, hipReadModeElementType> tex;}
\DoxyCodeLine{}
\DoxyCodeLine{\_\_global\_\_ void tex2dKernel(hipLaunchParm lp, float* outputData,}
\DoxyCodeLine{                             int width,}
\DoxyCodeLine{                             int height)}
\DoxyCodeLine{\{}
\DoxyCodeLine{    int x = blockIdx.x*blockDim.x + threadIdx.x;}
\DoxyCodeLine{    int y = blockIdx.y*blockDim.y + threadIdx.y;}
\DoxyCodeLine{    outputData[y*width + x] = tex2D(tex, x, y);}
\DoxyCodeLine{\}}

\end{DoxyCode}
 
\begin{DoxyCode}{0}
\DoxyCodeLine{// Host code:}
\DoxyCodeLine{}
\DoxyCodeLine{texture<float, 2, hipReadModeElementType> tex;}
\DoxyCodeLine{}
\DoxyCodeLine{void myFunc ()}
\DoxyCodeLine{\{}
\DoxyCodeLine{    // ...}
\DoxyCodeLine{}
\DoxyCodeLine{    textureReference* texref;}
\DoxyCodeLine{    hipModuleGetTexRef(\&texref, Module1, "{}tex"{});}
\DoxyCodeLine{    hipTexRefSetAddressMode(texref, 0, hipAddressModeWrap);}
\DoxyCodeLine{    hipTexRefSetAddressMode(texref, 1, hipAddressModeWrap);}
\DoxyCodeLine{    hipTexRefSetFilterMode(texref, hipFilterModePoint);}
\DoxyCodeLine{    hipTexRefSetFlags(texref, 0);}
\DoxyCodeLine{    hipTexRefSetFormat(texref, HIP\_AD\_FORMAT\_FLOAT, 1);}
\DoxyCodeLine{    hipTexRefSetArray(texref, array, HIP\_TRSA\_OVERRIDE\_FORMAT);}
\DoxyCodeLine{}
\DoxyCodeLine{   // ...}
\DoxyCodeLine{\}}

\end{DoxyCode}
 